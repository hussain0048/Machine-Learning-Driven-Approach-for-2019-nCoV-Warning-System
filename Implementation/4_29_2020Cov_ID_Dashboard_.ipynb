{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4-29-2020Cov-ID Dashboard .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hussain0048/Predict-assigment-submission-using--ML/blob/master/PredictNextAssigment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMaTt-5yvUDc",
        "colab_type": "text"
      },
      "source": [
        "## Table of Contents\n",
        "\n",
        "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
        "\n",
        "<font size = 3> \n",
        "1. <a href=\"#item1\">Importing Needed Libary</a>  \n",
        "2. <a href=\"#item2\">Colab Upgradation</a>  \n",
        "3. <a href=\"#item3\">Upload the Dataset</a>  \n",
        "4. <a href=\"#item4\">Read Dataset</a> \n",
        "5. <a href=\"#item5\">Data preprocessing</a> \n",
        "4.1 <a href=\"#item5\">Dataset Editing</a> \n",
        "4.2 <a href=\"#item5\">Data Description and analysis</a> \n",
        "4.3 <a href=\"#item5\">Missing values</a> \n",
        "4.4 <a href=\"#item5\">Data Sorting</a> \n",
        "4.5 <a href=\"#item5\">Data Encoding into Categorical</a> \n",
        "4.4 <a href=\"#item5\">Data Sorting</a> \n",
        "4.4 <a href=\"#item5\">Data Sorting</a> \n",
        " \n",
        "</font>\n",
        "</div># New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbTL0mLS5XLo",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "1.   **Importing Needed Libary** \n",
        "\n",
        "This program are used to used artifical recourrent neural network called short long term memory (LSTM)\n",
        "    predicting next week death cases of different state\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSX92Kj0G665",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt #6\n",
        "plt.style.use('fivethirtyeight') #7\n",
        "import math  #1\n",
        "import pandas\n",
        "import pandas_datareader as web #2\n",
        "from sklearn.preprocessing import MinMaxScaler  #3\n",
        "from keras.models import Sequential #4 \n",
        "from keras.layers import Dense, LSTM #5\n",
        "import pandas as pd # selected\n",
        "import pylab as pl\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy\n",
        "import scipy\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
        "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import preprocessing\n",
        "from sklearn.tree import export_graphviz\n",
        "from sklearn.externals.six import StringIO  \n",
        "from IPython.display import Image  \n",
        "import pydotplus\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from pandas.plotting import scatter_matrix\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRdnMRskS8N1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#[3]\n",
        "Enrol_window = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rzl0FkXmK1AY",
        "colab_type": "text"
      },
      "source": [
        " 2.**Colab Upgradation** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGsk7x5Tna9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This command is used to update the latest version of tensorflow inside colab\n",
        "!pip install tensorflow==1.14.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Z53WTKdAj4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSo57tJe6AaC",
        "colab_type": "text"
      },
      "source": [
        "3.**Upload the Dataset**\n",
        "\n",
        "  This module is used to upload dataset from Hardisk "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o3x_F3IWbht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this code is used to upload dataset from Pc to colab\n",
        "from google.colab import files # Please First run this cod in chrom \n",
        "def getLocalFiles():\n",
        "    _files = files.upload() # upload StudentNextSessionf.csv datase\n",
        "    if len(_files) >0: # Then run above  libray \n",
        "       for k,v in _files.items():\n",
        "         open(k,'wb').write(v)\n",
        "getLocalFiles()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MP2UU-zE62DM",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "4.  **Read Dataset**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoh_zm51WnO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##https://www.pluralsight.com/guides/handling-categorical-data-in-machine-learning-models\n",
        "#https://machinelearningmastery.com/power-transform-time-series-forecast-data-python/\n",
        "#df = pd.read_excel (r'Path where the Excel file is stored\\File name.xlsx')\n",
        "#https://www.shanelynn.ie/select-pandas-dataframe-rows-and-columns-using-iloc-loc-and-ix/\n",
        "df = pd.read_csv(r\"data_cases.csv\", header=0,index_col=0) # [1]\n",
        "X = df.iloc[:,0:3]\n",
        "y = df.iloc[:,3]\n",
        "#df= web.DataReader('AAPL', data_source='yahoo', start='2012', end='2019-12-17') [1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJRX-_KKmAgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [2]\n",
        "df = pandas.read_csv('Xdata.csv',usecols=['Date','State','Recovered','Deaths'])\n",
        "#dataframe.drop(dataframe.index[[16452,16453]])\n",
        "X= df.values\n",
        "len(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRz5xQGHRWrB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('Xdata.csv', index_col='Date', parse_dates=['Date'])\n",
        "df.head() # [3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8QEfc2Evza1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv\n",
        "!gdown --id 1AsfdLrGESCQnRW5rbMz56A1KBc3Fe5aV # [10] read dataset from google drive\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6rDOZpClbZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Removing unwanted Columns from the Data Frame [16]\n",
        "data = data.drop('Date',axis=1) \n",
        "data = data.drop('Adj Close',axis = 1)\n",
        "print('\\n\\nData after removing Date and Adj Close : ')\n",
        "print(data.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pl4_Vcie85p5",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "5.**Data preprocessing**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pT3ekeKYCYfr",
        "colab_type": "text"
      },
      "source": [
        " **5.1 Dataset Editing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swOcYkYrCRSj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " d3=dataframe2.iloc[:-1] # [4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cj3AyzLZF3R2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert the datafram to a numpy array\n",
        "dataset=data.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KB9b4xdOrH59",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.iloc[:, 4:] # taking first foure colum [10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FnbVCtWRTzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#removing all rows with zero values on their confirmed field[13]\n",
        "df = df[df[\"Confirmed\"] > 0]\n",
        "df.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB-4-4CHxa_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Split data into predictors and target [14]\n",
        "concrete_data_columns = concrete_data.columns\n",
        "predictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']] # all columns except Strength\n",
        "target = concrete_data['Strength'] # Strength column"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaGc_loUBjRH",
        "colab_type": "text"
      },
      "source": [
        "5.2  **Data Description and analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjBH1EXroPmh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.describe() #[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBEKOpF-pjQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.columns #[2] show colums in dataset "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gqyio6sxpx2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.astype(str)# [2] Convert dataset into string "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zF6e2mtMErz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.shape # Dimension of datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpko9Z7cE31t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head(10) # we will see first 10 row of the dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuRp5yD64AGa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "daily_cases.shape # Test [10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EixOwc_oQVnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Top 10 Countries by Confirmed Cases, Deaths & Recoveries [13]\n",
        "grouped_df = df.groupby(\"County\").max()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxpg7mg9X-OR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Confirmed cases[13]\n",
        "print(grouped_df.sort_values(\"Confirmed\", ascending=False)[\"Confirmed\"][:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLT33ParYdAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Deaths [13]\n",
        "print(grouped_df.sort_values(\"Deaths\", ascending=False)[\"Deaths\"][:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7-2_F6qYvZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Recoveries\n",
        "print(grouped_df.sort_values(\"Recovered\", ascending=False)[\"Recovered\"][:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "udLxKyKMuWc6"
      },
      "source": [
        "**5.3 Missing Values**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDAulKRvqsCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### finding all columns that have nan:[2]\n",
        "droping_list_all=[]\n",
        "for j in range(1,4):\n",
        "    if not df.iloc[:, j].notnull().all():\n",
        "        droping_list_all.append(j)        \n",
        "        #print(df.iloc[:,j].unique())\n",
        "droping_list_all"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wX6WfCfZq-wy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# filling nan with mean in any columns [2]\n",
        "for j in range(2,4):        \n",
        "        df.iloc[:,j]=df.iloc[:,j].fillna(df.iloc[:,j].mean())  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OxXAMDvrPZV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# another sanity check to make sure that there are not more any nan\n",
        "df.isnull().sum()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGPHMsWg8yU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Count the Null Columns [14]\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "null_columns=train.columns[train.isnull().any()]\n",
        "train[null_columns].isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDELWczZ9CvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Single Column Is Null [14]\n",
        "print(train[train[\"Electrical\"].isnull()][null_columns])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r25aSrQ_9Lyd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#All Null Columns[14]\n",
        "print(train[train.isnull().any(axis=1)][null_columns].head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyPgneFu_v7J",
        "colab_type": "text"
      },
      "source": [
        "**5.4 Data Sorting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EYw6AtRAXPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=df.sort_values('Date') #[4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fONM5PbRxJPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# testing [10]\n",
        "daily_cases = df.sum(axis=0)\n",
        "daily_cases.index = pd.to_datetime(daily_cases.index)\n",
        "daily_cases.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTghoeL4C_Cn",
        "colab_type": "text"
      },
      "source": [
        " *5.5*  **Data Encoding into Categorical**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OWLnFO3fgoE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#=============================================================>Encoding categorical data\n",
        "#https://discuss.analyticsvidhya.com/t/error-could-not-convert-string-to-float-while-running-randomforest-model-in-python/4855/2\n",
        "#https://medium.com/@contactsunny/label-encoder-vs-one-hot-encoder-in-machine-learning-3fc273365621\n",
        "##https://www.pluralsight.com/guides/handling-categorical-data-in-machine-learning-models\n",
        "feature_cols = ['Student ID', 'final_result','num_of_prev_attempts','Age','highest_education','Region','Gender','disability','date_submitted','studied_credits','score','sum_click']\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder_X = LabelEncoder()\n",
        "X[:,0] = labelencoder_X.fit_transform(X[:,0])\n",
        "X[:,1] = labelencoder_X.fit_transform(X[:,1])\n",
        "X[:,2] = labelencoder_X.fit_transform(X[:,2])\n",
        "X[:,3] = labelencoder_X.fit_transform(X[:,3])\n",
        "X[:,4] = labelencoder_X.fit_transform(X[:,4])\n",
        "X[:,5] = labelencoder_X.fit_transform(X[:,5])\n",
        "X[:,6] = labelencoder_X.fit_transform(X[:,6])\n",
        "X[:,7] = labelencoder_X.fit_transform(X[:,7])\n",
        "X[:,8] = labelencoder_X.fit_transform(X[:,8])\n",
        "X[:,9] = labelencoder_X.fit_transform(X[:,9])\n",
        "X[:,10] = labelencoder_X.fit_transform(X[:,10])\n",
        "X[:,11] = labelencoder_X.fit_transform(X[:,11])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUWjXWnMEQK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for classification we need to divide our target variable into categories\n",
        "from keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmR5mrIhEQIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5F8biWQz4mq5",
        "colab_type": "text"
      },
      "source": [
        "*4.6*  **Data Normalizaton**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-k0DTjiz2Qq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalize the data by substracting the mean and dividing by the standard deviation [14]\n",
        "# Data normaliz for regression model\n",
        "concrete_data_columns = concrete_data.columns\n",
        "predictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']] # all columns except Strength\n",
        "target = concrete_data['Strength'] # Strength column"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooJN9wu2tYa4",
        "colab_type": "text"
      },
      "source": [
        "**5.0 Statiscial Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2eXsqXYpm8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Correlations among columns [2]\n",
        "plt.matshow(df.corr(method='spearman'),vmax=1,vmin=-1,cmap='PRGn')\n",
        "plt.title('without resampling', size=15)\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZwUcDjSEIih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalize the dataset\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "dataset = scaler.fit_transform(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dmLdRYDB84U",
        "colab_type": "text"
      },
      "source": [
        "6. **Data Ploting**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFzAWsNfBWKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ploting [4]\n",
        "plt.figure(figsize = (18,9))\n",
        "plt.plot(range(df.shape[0]),(df['Recovered']+df['Deaths'])/2.0)\n",
        "plt.xticks(range(0,df.shape[0],500),df['Date'].loc[::500],rotation=45)\n",
        "plt.xlabel('Date',fontsize=18)\n",
        "plt.ylabel('Death and Recoverd',fontsize=18)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MOK018gFf-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.hist(column='Deaths', bins=50) # PLOT histogram from dataset \n",
        "plt.show ()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFu9c2SfLDRN",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NWno337-z89f",
        "colab": {}
      },
      "source": [
        "#  plot diagram (1)\n",
        "def plot_features_distribution(features, title,isLog=False):                \n",
        "    plt.figure(figsize=(12,6))\n",
        "    plt.title(title)\n",
        "    for feature in features:\n",
        "        if(isLog):\n",
        "            sns.distplot(np.log1p(df[feature]),kde=True,hist=False, bins=120, label=feature)\n",
        "        else:\n",
        "            sns.distplot(df[feature],kde=True,hist=False, bins=120, label=feature)\n",
        "    plt.xlabel('')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "67xm9epV0JJC",
        "colab": {}
      },
      "source": [
        "# plot diagram (2)\n",
        "def plot_count(feature, title,size=1,df=df):\n",
        "    f, ax = plt.subplots(1,1, figsize=(4*size,4))\n",
        "    total = float(len(df))\n",
        "    g = sns.countplot(df[feature], order = df[feature].value_counts().index[:30], palette='Set3')\n",
        "    g.set_title(\"Number and percentage of {}\".format(title))\n",
        "    if(size > 2):\n",
        "        plt.xticks(rotation=90, size=8)\n",
        "    for p in ax.patches:\n",
        "        height = p.get_height()\n",
        "        ax.text(p.get_x()+p.get_width()/2.,\n",
        "                height + 3,\n",
        "                '{:1.2f}%'.format(100*height/total),\n",
        "                ha=\"center\") \n",
        "    plt.show()   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WtUMzmIl0YXh",
        "colab": {}
      },
      "source": [
        "# plot diagram (3)\n",
        "plot_count('State','Confirmed')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvIrPaXRUi2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Bar Chart [7,8]\n",
        "df=df[:57]\n",
        "df.plot('State',['Recovered','Deaths'],kind = 'bar') # Kind=Bar, line, box\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QSi_2eVjC_I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [9]\n",
        "from matplotlib import pyplot\n",
        "pyplot.figure(1)\n",
        "# line plot\n",
        "pyplot.subplot(211)\n",
        "pyplot.plot(Date)\n",
        "# histogram\n",
        "pyplot.subplot(212)\n",
        "pyplot.hist(Deate)\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhqXHGV0Lgcq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://www.datacamp.com/courses/preprocessing-for-machine-learning-in-python\n",
        "#https://www.geeksforgeeks.org/data-preprocessing-machine-learning-python/\n",
        "#https://towardsdatascience.com/introduction-to-data-preprocessing-in-machine-learning-a9fa83a5dc9d\n",
        "#https://machinelearningmastery.com/prepare-data-machine-learning-python-scikit-learn/\n",
        "#https://medium.com/data-py-blog/data-preprocessing-for-python-2ab52cbc0edd\n",
        "#https://medium.com/datadriveninvestor/data-preprocessing-for-machine-learning-188e9eef1d2c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7r5nhwzKdFT",
        "colab_type": "text"
      },
      "source": [
        " 7.**Feature Importance**\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngVFSyIiKz8u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#How to Calculate Feature Importance With Python\n",
        "#https://machinelearningmastery.com/calculate-feature-importance-with-python/?fbclid=IwAR0uvlTGLX2qDJ8bu78fo8HQxq2msGX6mbu9QIQzw9YdUPKeZrOB8Mf4_44\n",
        "#https://machinelearningmastery.com/calculate-feature-importance-with-python/\n",
        " from sklearn.datasets import make_regression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from matplotlib import pyplot\n",
        "x1=atop(X);\n",
        "model = RandomForestRegressor()\n",
        "# fit the model\n",
        "model.fit(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQDUyjWsDbZo",
        "colab_type": "text"
      },
      "source": [
        "8.**Data Spliting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prGtyX2iaBLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdHiejJ2R5b7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [3]\n",
        "feature_train, label_train, feature_test, label_test = load_data(df, 'Deaths', Enrol_window, True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L_zdec1SPoH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(datasetname, column, seq_len, normalise_window):\n",
        "    # A support function to help prepare datasets for an RNN/LSTM/GRU\n",
        "    data = datasetname.loc[:,column]\n",
        "\n",
        "    sequence_length = seq_len + 1\n",
        "    result = []\n",
        "    for index in range(len(data) - sequence_length):\n",
        "        result.append(data[index: index + sequence_length])\n",
        "    \n",
        "    if normalise_window:\n",
        "        #result = sc.fit_transform(result)\n",
        "        result = normalise_windows(result)\n",
        "\n",
        "    result = np.array(result)\n",
        "     #Last 10% is used for validation test, first 90% for training\n",
        "    row = round(0.9 * result.shape[0])\n",
        "    train = result[:int(row), :]\n",
        "    np.random.shuffle(train)\n",
        "    x_train = train[:, :-1]\n",
        "    y_train = train[:, -1]\n",
        "    x_test = result[int(row):, :-1]\n",
        "    y_test = result[int(row):, -1]\n",
        "\n",
        "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
        "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))  \n",
        "\n",
        "    return [x_train, y_train, x_test, y_test]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kJQYO1ZSYuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [3]\n",
        "def normalise_windows(window_data):\n",
        "    # A support function to normalize a dataset\n",
        "    normalised_data = []\n",
        "    for window in window_data:\n",
        "        normalised_window = [((float(p) / float(window[0])) - 1) for p in window]\n",
        "        normalised_data.append(normalised_window)\n",
        "    return normalised_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_tdcIaGq32o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create the training dataset\n",
        "# create the scaled training dataset\n",
        "train_data=scaled_data[0:training_data_len,:]\n",
        "# split the data into x_train and y_train dataset\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "for i in range (50, len(train_data)):\n",
        "  x_train.append(train_data[i-50:i,0])\n",
        "  y_train.append(train_data[i,0])\n",
        "  if i<= 51:\n",
        "    print(x_train)\n",
        "    print(y_train)\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7l1O6TJaxr3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert the x_train and y_train to numpy arrays\n",
        "x_train, y_train = np.array(x_train), np.array(y_train)\n",
        "x_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On-pcXAqcJGG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshap the data\n",
        "x_train=np.reshape(x_train, (x_train.shape[0], x_train.shape[1],1))\n",
        "x_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2WbDQA3maFZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Split into train and test data [16]\n",
        "data_X = data.loc[:,data.columns !=  'Close' ]\n",
        "data_Y = data['Close']\n",
        "train_X, test_X, train_y,test_y = train_test_split(data_X,data_Y,test_size=0.25)\n",
        "print('\\n\\nTraining Set')\n",
        "print(train_X.head())\n",
        "print(train_y.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SN9GM4UrD_W3",
        "colab_type": "text"
      },
      "source": [
        "9.**Building Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhZR8yOwETba",
        "colab_type": "text"
      },
      "source": [
        "9.1  **Decision Tree Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzSi_BST2TJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://www.datacamp.com/community/tutorials/decision-tree-classification-python\n",
        "# Create Decision Tree classifer object\n",
        "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\n",
        "# Train Decision Tree Classifer\n",
        "clf = clf.fit(X_train,y_train)\n",
        "#Predict the response for test dataset\n",
        "y_pred = clf.predict(X_test)\n",
        "print(y_pred)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6T6ktFVYdd_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build the LSTM model\n",
        "model=Sequential()\n",
        "model.add(LSTM(40, return_sequences=True,input_shape=(x_train.shape[1],1)))\n",
        "model.add(LSTM(40, return_sequences=False))\n",
        "model.add(Dense(25))\n",
        "model.add(Dense(1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8B53I7gnv3F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile the model\n",
        "model.compile(optimizer='adam',loss='mean_squared_error')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asZwD5jhoXk9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train the model\n",
        "model.fit(x_train,y_train,batch_size=1,epochs=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qECXeVx1vy9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data=scaled_data[training_data_len -40:,:]\n",
        "x_test= []\n",
        "y_test = dataset[training_data_len:,:]\n",
        "for i in range(50, len(test_data)):\n",
        "  x_test.append(test_data[i -50:i,0])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfuKDYyExdz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test=np.array(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM_5z8cExsSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test=np.reshape(x_test,(x_test.shape[0], x_test.shape[1],1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jk7qbLkYyjhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions=model.predict(x_test)\n",
        "predictions=scaler.inverse_transform(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgZ1BGWyzVaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rmse=np.sqrt(np.mean(predictions - y_test)**2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28nSDcQAaPsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaIXIV8vPPzg",
        "colab_type": "text"
      },
      "source": [
        "6.2  **KNN Classifier** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQlL-JQYWe3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "k = 1\n",
        "#Train Model and Predict  \n",
        "neigh = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\n",
        "y_pred = neigh.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sv3ZMg7qXBJ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "print(\"Train set Accuracy: \", metrics.accuracy_score(y_train, neigh.predict(X_train)))\n",
        "print(\"Test set Accuracy: \", metrics.accuracy_score(y_test, yhat))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P14FdEkQXF1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can calculate the accuracy of KNN for different Ks.\n",
        "Ks = 10\n",
        "mean_acc = np.zeros((Ks-1))\n",
        "std_acc = np.zeros((Ks-1))\n",
        "ConfustionMx = [];\n",
        "for n in range(1,Ks):\n",
        "    \n",
        "    #Train Model and Predict  \n",
        "    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n",
        "    yhat=neigh.predict(X_test)\n",
        "    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)\n",
        "\n",
        "    \n",
        "    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])\n",
        "\n",
        "mean_acc\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGZJSorVXRzp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot  model accuracy  for Different number of Neighbors \n",
        "plt.plot(range(1,Ks),mean_acc,'g')\n",
        "plt.fill_between(range(1,Ks),mean_acc - 1 * std_acc,mean_acc + 1 * std_acc, alpha=0.10)\n",
        "plt.legend(('Accuracy ', '+/- 3xstd'))\n",
        "plt.ylabel('Accuracy ')\n",
        "plt.xlabel('Number of Nabors (K)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qY94l-DXBIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print( \"The best accuracy was with\", mean_acc.max(), \"with k=\", mean_acc.argmax()+1) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMnJfVQOQTob",
        "colab_type": "text"
      },
      "source": [
        "6.3  **Logistic Rregression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3qQWXzV4H2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://www.marktechpost.com/2019/06/12/logistic-regression-with-a-real-world-example-in-python/?fbclid=IwAR31FyvXdFxxWam-n6lCKmsBxA7m_MIHdrhwerqpqow1-V9dx2ZeQ_gq-s0\n",
        "classifier = LogisticRegression(random_state=0)\n",
        "classifier.fit(X_train, y_train)\n",
        "y_pred = classifier.predict(X_test)\n",
        "print(y_pred)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJHwOa0KRB4X",
        "colab_type": "text"
      },
      "source": [
        "6.4  **Random Forest Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTZGi49RT3la",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# =========================================================================> RandomForestClassifier================\n",
        "#https://www.kaggle.com/willkoehrsen/visualize-a-decision-tree-w-python-scikit-learn\n",
        "#https://www.kaggle.com/willkoehrsen/visualize-a-decision-tree-w-python-scikit-learn\n",
        "# Limit max depth\n",
        "model = RandomForestClassifier(max_depth = 3, n_estimators=12)\n",
        "# Train\n",
        "model.fit(X_train, y_train)\n",
        "#Predict the response for test dataset\n",
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVb6yvuLLdVn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extract single tree\n",
        "estimator_limited = model.estimators_[5]\n",
        "estimator_limited\n",
        "# No max depth\n",
        "model = RandomForestClassifier(max_depth = 3, n_estimators=10)\n",
        "model.fit(X_train, y_train)\n",
        "estimator_nonlimited = model.estimators_[5]\n",
        "\n",
        "from sklearn.tree import export_graphviz\n",
        "export_graphviz(estimator_limited, out_file='tree_limited.dot', feature_names =feature_cols,\n",
        "                class_names = y,\n",
        "                rounded = True, proportion = False, precision = 2, filled = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5b3WT4hViYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "export_graphviz(estimator_nonlimited, out_file='tree_nonlimited.dot', feature_names = feature_cols,\n",
        "                class_names =y,\n",
        "                rounded = True, proportion = False, precision = 2, filled = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXMsWMjgWnsm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Convert to png from the command line\n",
        "!dot -Tpng tree_limited.dot -o tree_limited.png -Gdpi=600"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n284gqLAQzSb",
        "colab_type": "text"
      },
      "source": [
        "6.4  **ANN** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaPXtuXvRbt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#==============================================================================================================================================================\n",
        "#                                                                Evaluating Model\n",
        "#===============================================================================================================================================================\n",
        "\n",
        "#=============================================================> accuracy \n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sdd3fQaQWrNO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image\n",
        "Image(filename = 'tree_limited.png')\n",
        "\n",
        "#======================================================== build CNN\n",
        "#https://www.tensorflow.org/tutorials/estimators/cnn\n",
        "import tensorflow as tf\n",
        "def cnn_model_f(features,labels, mod):\n",
        "  # input layer\n",
        "  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
        "  # Convolutional Layer #1\n",
        "  conv1 = tf.layers.conv2d(\n",
        "      inputs=input_layer,\n",
        "      filters=32,\n",
        "      kernel_size=[5, 5],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu)\n",
        "# Pooling Layer #1\n",
        "  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
        "  # Convolutional Layer #2 and Pooling Layer #2\n",
        "  conv2 = tf.layers.conv2d(\n",
        "      inputs=pool1,\n",
        "      filters=64,\n",
        "      kernel_size=[5, 5],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu)\n",
        "  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
        "  # Dense Layer\n",
        "  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
        "  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
        "  dropout = tf.layers.dropout(\n",
        "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
        "  # Logits Layer\n",
        "  logits = tf.layers.dense(inputs=dropout, units=10)\n",
        "  predictions = {\n",
        "      # Generate predictions (for PREDICT and EVAL mode)\n",
        "      \"classes\": tf.argmax(input=logits, axis=1),\n",
        "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
        "      # `logging_hook`.\n",
        "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
        "  }\n",
        "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
        "\n",
        "  # Calculate Loss (for both TRAIN and EVAL modes)\n",
        "  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
        "\n",
        "  # Configure the Training Op (for TRAIN mode)\n",
        "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
        "    train_op = optimizer.minimize(\n",
        "        loss=loss,\n",
        "        global_step=tf.train.get_global_step())\n",
        "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
        "\n",
        "  # Add evaluation metrics (for EVAL mode)\n",
        "  eval_metric_ops = {\n",
        "      \"accuracy\": tf.metrics.accuracy(\n",
        "          labels=labels, predictions=predictions[\"classes\"])\n",
        "  }\n",
        "  return tf.estimator.EstimatorSpec(\n",
        "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdWT57wSmxP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#==============================================================> Making the Confusion Matrix\n",
        "# https://www.marktechpost.com/2019/06/12/logistic-regression-with-a-real-world-example-in-python/?fbclid=IwAR31FyvXdFxxWam-n6lCKmsBxA7m_MIHdrhwerqpqow1-V9dx2ZeQ_gq-s0\n",
        "# https://www.geeksforgeeks.org/confusion-matrix-machine-learning/\n",
        "#https://stackoverflow.com/questions/30746460/how-to-interpret-scikits-learn-confusion-matrix-and-classification-report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(y_test.size)\n",
        "ACC=( cm[0][0] + cm[1][1] ) / ( 117 )\n",
        "print('Accuracy',ACC)\n",
        "\n",
        "print('Accuracy Score :',accuracy_score(y_test, y_pred)) \n",
        "print('Report : ', classification_report(y_test, y_pred)) \n",
        "print(confusion_matrix)\n",
        "print('\\nConfussion matrix:\\n',confusion_matrix(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKhofH_7Rswy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualizing Decision Trees\n",
        "dot_data = StringIO()\n",
        "export_graphviz(clf, out_file=dot_data,  \n",
        "                filled=True, rounded=True,\n",
        "                special_characters=True,feature_names = feature_cols,class_names=['Not-submitted','Submitted'])\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "graph.write_png('StudentNextSessionf.png')\n",
        "Image(graph.create_png())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDDTGM0Nkg1E",
        "colab_type": "text"
      },
      "source": [
        " **References**\n",
        " \n",
        "1.   [1] Stock Price Prediction Using Python & Machine Learning\n",
        "      https://www.youtube.com/watch?v=QIUxPv5PJOY\n",
        "\n",
        "2.   [2] Time-series data analysis using LSTM (Tutorial)\n",
        "https://www.kaggle.com/amirrezaeian/time-series-data-analysis-using-lstm-tutorial\n",
        "3. [3] Learn by example RNN/LSTM/GRU time series\n",
        "https://www.kaggle.com/charel/learn-by-example-rnn-lstm-gru-time-series\n",
        "4. [4] Stock Market Predictions with LSTM in Python\n",
        "https://www.datacamp.com/community/tutorials/lstm-python-stock-market\n",
        "5. [5] LSTM Time Series Prediction Tutorial using PyTorch in Python | Coronavirus Daily Cases Forecasting\n",
        "https://www.youtube.com/watch?v=8A6TEjG2DNw\n",
        "6. [6] LSTM Time Series Prediction Tutorial using PyTorch in Python | Coronavirus Daily Cases Forecasting\n",
        "https://morioh.com/p/5a74f94cfd6b\n",
        "7.[7] Pandas Dataframe: Plot Examples with Matplotlib and Pyplot\n",
        "http://queirozf.com/entries/pandas-dataframe-plot-examples-with-matplotlib-pyplot\n",
        "8.[8]Dataframe Visualization with Pandas Plot\n",
        "https://kanoki.org/2019/09/16/dataframe-visualization-with-pandas-plot/\n",
        "9.[9]How to Use Power Transforms for Time Series Forecast Data with Python\n",
        "https://machinelearningmastery.com/power-transform-time-series-forecast-data-python/\n",
        "10.[10] Time Series Forecasting with LSTMs for Daily Coronavirus Cases using PyTorch in Python\n",
        "https://www.curiousily.com/posts/time-series-forecasting-with-lstm-for-daily-coronavirus-cases/\n",
        "11. [11] Building COVID-19 interactive dashboard from Jupyter Notebook https://morioh.com/p/127b5a302cb1?fbclid=IwAR28dsncAPM184LyzEhJCMxsCx5im2X4XJp3gSULd9Tq70XTivsMH75piLg\n",
        "12. [12] How to Calculate Precision, Recall, F1, and More for Deep Learning Models\n",
        "https://machinelearningmastery.com/how-to-calculate-precision-recall-f1-and-more-for-deep-learning-models/?fbclid=IwAR30_eKuKXmIYbyiaMZdCDzhe9YPLaI-ATGjRj83U8mcjySuwikcaQt6Vfw\n",
        "13.[13] Data ETL & Analysis on the global and Mexican datasets of the COVID-19 pandemic\n",
        "https://github.com/PhantomInsights/covid-19\n",
        "14.[14]Regression Models with Keras\n",
        "https://colab.research.google.com/github/hussain0048/Deep-Learning-with-Keras/blob/master/DL0101EN-3-1-Regression-with-Keras-py-v1.0.ipynb#scrollTo=4ORZhKfduSrw\n",
        "15.[15] Pandas: Find Rows Where Column/Field Is Null\n",
        "https://dzone.com/articles/pandas-find-rows-where-columnfield-is-null\n",
        "16. [16] Analysis and Predicting Stock Trends with Python\n",
        "https://morioh.com/p/8e9d9d4161c5?f=5c21f93bc16e2556b555ab2f&fbclid=IwAR2oIByWVFfg-b7f1Phd3cZ84mwmp9LriMb0pobqdJa9TWV1-pK04YkHqH4\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}